{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the XOR function with a multilayer perceptron\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/199px-Colored_neural_network.svg.png\" align=\"right\">](https://en.wikipedia.org/wiki/Multilayer_perceptron)\n",
    "\n",
    "*From Wikipedia, the free encyclopedia*\n",
    "\n",
    "A [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP) is a feedforward artificial neural network model that maps sets of input data onto a set of appropriate outputs. An MLP consists of multiple layers of nodes in a directed graph, with each layer fully connected to the next one. Except for the input nodes, each node is a neuron (or processing element) with a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training the network. MLP is a modification of the standard linear perceptron and can distinguish data that are not linearly separable.\n",
    "\n",
    "Consequently, MLP can outperform the perceptron and solve the XOR problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from packages.plot import plot_decision_boundary, plot_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data\n",
    "\n",
    "This is the data for the truth table of the XOR function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[0.,0.],\\\n",
    "              [0.,1.],\\\n",
    "              [1.,0.],\\\n",
    "              [1.,1.]])\n",
    "y = np.array([0.,1.,1.,0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Create a [MLP object](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) with the following arguments:\n",
    "* [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) solver (standard technique in [backpropagation](https://en.wikipedia.org/wiki/Backpropagation))\n",
    "* one hidden layer with 5 neurons\n",
    "* 4000 iterations maximum\n",
    "\n",
    "The rest of the arguments are set to their default values (see documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = MLPClassifier(solver='sgd',\\\n",
    "                    hidden_layer_sizes=(5, ),\\\n",
    "                    max_iter=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "The `fit` function automatically iterates until convergence or the maximum number of iterations is reached, so you only need to execute the following cell once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data\n",
    "\n",
    "The following figure displays the XOR data and the decision boundary of the MLP. This boundary is not linear anymore: it is represented in colors, so that the blue region in the plane corresponds to the features that are classified as 0's and consequently the brown region is classified as 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(net,x,y)\n",
    "plot_data(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success or failure?\n",
    "\n",
    "There is not a unique solution to this problem. The figure below depicts some possible solutions:\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr><td>\n",
    "<img src=\"img/xor_1.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_2.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_3.png\" width=200>\n",
    "</td></tr><tr><td>\n",
    "<img src=\"img/xor_4.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_5.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_6.png\" width=200>\n",
    "</td></tr>\n",
    "</table>\n",
    "\n",
    "However, the network not always converge. Sometimes, it can get stuck in a local minima. The algorithm stops but the result is not correct at all. For example:\n",
    "\n",
    "<table border=\"0\">\n",
    "<tr><td>\n",
    "<img src=\"img/xor_fail_1.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_fail_2.png\" width=200>\n",
    "</td><td>\n",
    "<img src=\"img/xor_fail_3.png\" width=200>\n",
    "</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the network\n",
    "\n",
    "Percentage of correct classification of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.score(x,y) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of iterations during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss curve: (currently, [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) supports only the [Cross-Entropy loss function](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(net.loss_curve_);\n",
    "plt.xlabel('Iterations');\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
